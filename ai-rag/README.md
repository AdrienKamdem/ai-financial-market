# Human vs AI Text Classification

This project explores **binary text classification** to distinguish between **AI-generated** and **human-written** essays using a **Kaggle dataset**.  
The approach combines **state-of-the-art text embeddings** from a transformer model with a **custom Multi-Layer Perceptron (MLP)** classifier.

---

## Project Overview

- **Goal**: Detect whether a given text is generated by a human or by an AI system.
- **Dataset**: *AI Generated Essays Dataset* (from Kaggle).
- **Methodology**: 
  1. Use the transformer-based **all-MiniLM-L6-v2** model from [SentenceTransformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to generate high-quality 384-dimensional embeddings.
  2. Feed embeddings into a **3-layer MLP** for binary classification.
  3. Apply **regularization (L1 + L2)** and **weighted loss** to handle imbalanced data.
  4. Run a **grid search** across hyperparameters (hidden sizes, learning rate, optimizer, epochs, thresholds).

---

## Architecture

### Embedding Model
- **Model**: `all-MiniLM-L6-v2`  
- **Output**: 384-dimensional dense embedding vector per text.  
- **Reason**: One of the best-performing models on semantic similarity benchmarks while being lightweight and efficient.

### Classifier: MLP
- ** Input (384-dim) → FC(128) → ReLU → FC(64) → ReLU → FC(1) → Sigmoid
- ** Hidden layers: 128 and 64 neurons
- ** Final output: Binary classification (Human = 0, AI = 1)
- ** Loss: BCEWithLogitsLoss with pos_weight adjustment for imbalance
- ** Regularization: Elastic net (L1 + L2 penalties)
  
### Training Pipeline
1) Data Preprocessing
- ** Load CSV into a structured dictionary (DatasetProcessor class).
- ** Clean text (remove noise, normalize depending on embedding model).
- ** Encode text into embeddings.
- ** Train/test split (70/30, stratified).

2) Training
Grid search over:
- ** Hidden layer sizes: [128, 256], [64, 128]
- ** Batch sizes: [32, 64]
- ** Learning rates: [0.01, 0.001, 0.1]
- ** Optimizers: [SGD, Adam]
- ** Epochs: [10, 50, 100]
- ** Thresholds: tuned for imbalance [0.007 – 0.0095]
- ** L1 and L2 regularization to prevent overfitting.

3) Evaluation
- ** Metrics: Accuracy, Precision, Recall, F1-score
- ** Results saved in results.json and results.txt.
